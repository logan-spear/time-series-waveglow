{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make the cells wider in the browser window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, train_f=\"wind_power_data/wind_power_train.pickle\", test_f = \"wind_power_data/wind_power_test.pickle\", n=96, rolling=True, small_subset=False, directory='/Users/DanielSalz/Documents/Masters/Fall/CS236/time-series-waveglow'):\n",
    "        self.trainset = pd.read_pickle(directory+'/'+train_f).values\n",
    "        self.testset = pd.read_pickle(directory+'/'+test_f).values\n",
    "        self.m = self.trainset.shape[0]\n",
    "        self.m_test = self.testset.shape[0]\n",
    "        self.n = n\n",
    "        self.rolling = rolling\n",
    "        self.small_subset = small_subset\n",
    "        if self.rolling:\n",
    "            if small_subset:\n",
    "                self.sample_indices = np.random.choice(list(range(self.n, self.m-self.n+1)), 2000, replace=False)\n",
    "            else:\n",
    "                self.sample_indices = np.random.choice(list(range(self.n, self.m-self.n+1)), self.m-2*self.n, replace=False)\n",
    "        else:\n",
    "            self.sample_indices = np.random.choice(list(range(self.n, self.m-self.n+1, self.n)), int((self.m-self.n)/self.n), replace=False)\n",
    "        self.num_samples = self.sample_indices.shape[0]\n",
    "        self.sample_idx = 0\n",
    "        self.epoch_end = True\n",
    "\n",
    "    def sample(self, batch_size=24):\n",
    "\n",
    "        if self.sample_idx+batch_size >= self.num_samples:\n",
    "            self.epoch_end = False\n",
    "            indices = self.sample_indices[self.sample_idx:]\n",
    "            self.sample_idx = 0\n",
    "            if self.rolling:\n",
    "                if self.small_subset:\n",
    "                    self.sample_indices = np.random.choice(list(range(self.n, self.m-self.n+1)), 2000, replace=False)\n",
    "                else:\n",
    "                    self.sample_indices = np.random.choice(list(range(self.n, self.m-self.n+1)), self.m-2*self.n, replace=False)\n",
    "            else:\n",
    "                self.sample_indices = np.random.choice(list(range(self.n, self.m-self.n+1, self.n)), int((self.m-self.n)/self.n), replace=False)\n",
    "        else:\n",
    "            indices = self.sample_indices[self.sample_idx:self.sample_idx+batch_size]\n",
    "            self.sample_idx += batch_size\n",
    "\n",
    "        context = np.vstack([np.reshape(self.trainset[i-self.n:i], [1, self.n]) for i in indices])\n",
    "        context = context[:, :, None]\n",
    "\n",
    "        forecast = np.vstack([np.reshape(self.trainset[i:i+self.n], [1, self.n]) for i in indices])\n",
    "\n",
    "        return context, forecast\n",
    "\n",
    "    def test_samples(self, num_contexts=15):\n",
    "        indices = np.random.choice(list(range(self.n, self.m_test-self.n+1, self.n)), num_contexts, replace=False)\n",
    "        context = np.vstack([np.reshape(self.testset[i-self.n:i], [1, self.n]) for i in indices])\n",
    "        forecast = np.vstack([np.reshape(self.testset[i:i+self.n], [1, self.n]) for i in indices])\n",
    "\n",
    "        context = np.reshape(context, [num_contexts, self.n])\n",
    "        context = context[:, :, None]\n",
    "        forecast = np.reshape(forecast, [num_contexts, self.n])\n",
    "\n",
    "        return context, forecast\n",
    "    \n",
    "    def test_data(self):\n",
    "        context = np.vstack([np.reshape(self.testset[i:i+self.n], [1, self.n]) for i in range(self.test.shape[0]-self.n)])\n",
    "        forecast = np.vstack([np.reshape(self.testset[i:i+self.n], [1, self.n]) for i in range(self.n, self.test.shape[0])])\n",
    "        return context, forecast\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from DataLoader import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from waveglow_model import WaveGlow, WaveGlowLoss\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='argument parser')\n",
    "# parser.add_argument('--epochs', dest='epochs', type=int, default=100)\n",
    "# parser.add_argument('--rolling', dest='rolling', type=int, default=1)\n",
    "# parser.add_argument('--small_subset', dest='small_subset', type=int, default=0)\n",
    "# parser.add_argument('--use_gpu', dest='use_gpu', type=int, default=1)\n",
    "# parser.add_argument('--checkpointing', dest='checkpointing', type=int, default=1)\n",
    "# parser.add_argument('--generate_per_epoch', dest='generate_per_epoch', type=int, default=1)\n",
    "# parser.add_argument('--generate_final', dest='generate_final', type=int, default=1)\n",
    "# parser.add_argument('--batch_size', dest='batch_size', type=int, default=12)\n",
    "# parser.add_argument('--learning_rate', dest='learning_rate', type=float, default=1e-4)\n",
    "# parser.add_argument('--n_context_channels', dest='n_context_channels', type=int, default=96)\n",
    "# parser.add_argument('--n_flows', dest='n_flows', type=int, default=6)\n",
    "# parser.add_argument('--n_group', dest='n_group', type=int, default=24)\n",
    "# parser.add_argument('--n_early_every', dest='n_early_every', type=int, default=3)\n",
    "# parser.add_argument('--n_early_size', dest='n_early_size', type=int, default=6)\n",
    "# parser.add_argument('--n_layers', dest='n_layers', type=int, default=4)\n",
    "# parser.add_argument('--dilation_list', dest='dilation_list', type=str, default='1 1 2 2')\n",
    "# parser.add_argument('--n_channels', dest='n_channels', type=int, default=96)\n",
    "# parser.add_argument('--kernel_size', dest='kernel_size', type=int, default=3)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# args.rolling = True if args.rolling else False\n",
    "# args.small_subset = True if args.small_subset else False\n",
    "# args.use_gpu = True if args.use_gpu else False\n",
    "# args.checkpointing = True if args.checkpointing else False\n",
    "# args.dilation_list = [int(i) for i in args.dilation_list.split(' ')]\n",
    "\n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    assert(os.path.isfile(checkpoint_path))\n",
    "    checkpoint_dict = torch.load(checkpoint_path, map_location='cpu')\n",
    "    iteration = checkpoint_dict['iteration']\n",
    "    optimizer.load_state_dict(checkpoint_dict['optimizer'])\n",
    "    model_for_loading = checkpoint_dict['model']\n",
    "    model.load_state_dict(model_for_loading.state_dict())\n",
    "    print(\"Loaded checkpoint '%s' (iteration %d)\" % (checkpoint_path, iteration))\n",
    "    return model, optimizer, iteration\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, learning_rate, iteration, filepath, use_gpu=True):\n",
    "    print(\"Saving model and optimizer state at iteration %d to %s\" % (iteration, filepath))\n",
    "\n",
    "\n",
    "    model_for_saving = model\n",
    "\n",
    "    model_for_saving.load_state_dict(model.state_dict())\n",
    "    torch.save({'model': model_for_saving,\n",
    "                'iteration': iteration,\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'learning_rate': learning_rate}, filepath)\n",
    "\n",
    "\n",
    "# n_context_channels=96, n_flows=6, n_group=24, n_early_every=3, n_early_size=8, n_layers=2, dilation_list=[1,2], n_channels=96, kernel_size=3, use_gpu=True\n",
    "def training_procedure(dataset=None, num_gpus=0, output_directory='./train', epochs=1000, learning_rate=1e-4, batch_size=12, checkpointing=True, checkpoint_path=\"./checkpoints\", seed=2019, params = [96, 6, 24, 3, 8, 2, [1,2], 96, 3], use_gpu=True, gen_tests=False):\n",
    "    print(\"#############\")\n",
    "    params.append(use_gpu)\n",
    "    torch.manual_seed(seed)\n",
    "    if use_gpu:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "    if not os.path.isdir(output_directory[2:]): os.mkdir(output_directory[2:])\n",
    "    if checkpointing and not os.path.isdir(checkpoint_path[2:]): os.mkdir(checkpoint_path[2:])\n",
    "    criterion = WaveGlowLoss()\n",
    "    model = WaveGlow(*params)\n",
    "    if use_gpu:\n",
    "        model.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # iteration = 0\n",
    "    # if checkpoint_path != \"\":\n",
    "        # model, optimizer, iteration = load_checkpoint(checkpoint_path, model, optimizer)\n",
    "\n",
    "        # iteration += 1\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    loss_iteration = []\n",
    "    for epoch in range(epochs):\n",
    "        iteration = 0\n",
    "        print(\"Epoch: %d/%d\" % (epoch+1, epochs))\n",
    "        avg_loss = []\n",
    "        while(dataset.epoch_end):\n",
    "            # model.zero_grad()\n",
    "            context, forecast = dataset.sample(batch_size)\n",
    "\n",
    "            if use_gpu:\n",
    "                forecast = torch.autograd.Variable(torch.cuda.FloatTensor(forecast))\n",
    "                context = torch.autograd.Variable(torch.cuda.FloatTensor(context))\n",
    "            else:\n",
    "                forecast = torch.autograd.Variable(torch.FloatTensor(forecast))\n",
    "                context = torch.autograd.Variable(torch.FloatTensor(context))\n",
    "\n",
    "            z, log_s_list, log_det_w_list, early_out_shapes = model(forecast, context)\n",
    "\n",
    "            loss = criterion((z, log_s_list, log_det_w_list))\n",
    "            reduced_loss = loss.item()\n",
    "            loss_iteration.append(reduced_loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            avg_loss.append(reduced_loss)\n",
    "            optimizer.step()\n",
    "            print(\"Model waveglow_ncontextchannels-%d_nflows-%d_ngroup-%d-nearlyevery-%d-nearlysize-%d-nlayers-%d_dilations-%s_nchannels_%d-kernelsize-%d-lr-%.5f_seed-%d\" % (params[0], params[1], params[2], params[3], params[4], params[5], str(params[6]), params[7], params[8], learning_rate, seed))\n",
    "            print(\"On iteration %d with loss %.4f\" % (iteration, reduced_loss))\n",
    "            iteration += 1\n",
    "            # if (checkpointing and (iteration % iters_per_checkpoint == 0)):\n",
    "# n_context_channels=96, n_flows=6, n_group=24, n_early_every=3, n_early_size=8, n_layers=2, dilation_list=[1,2], n_channels=96, kernel_size=3, use_gpu=True      epochs=1000, learning_rate=1e-4, batch_size=12, checkpointing=True, checkpoint_path=\"./checkpoints\", seed=2019, params = [96, 6, 24, 3, 8, 2, [1,2], 96, 3], use_gpu=True, gen_tests=True):\n",
    "        if gen_tests: generate_tests(dataset, model, 5, 96, use_gpu, str(epoch+1))\n",
    "        epoch_loss = sum(avg_loss)/len(avg_loss)\n",
    "        if checkpointing:\n",
    "            checkpoint_path = \"%s/waveglow_ncontextchannels-%d_nflows-%d_ngroup-%d-nearlyevery-%d-nearlysize-%d-nlayers-%d_dilations-%s_nchannels_%d-kernelsize-%d-lr-%.5f_seed-%d_epoch-%d_loss-%.4f\" % (output_directory, params[0], params[1], params[2], params[3], params[4], params[5], str(params[6]), params[7], params[8], learning_rate, seed, epoch, epoch_loss)\n",
    "            save_checkpoint(model, optimizer, learning_rate, iteration, checkpoint_path, use_gpu)\n",
    "\n",
    "        dataset.epoch_end = True\n",
    "        \n",
    "    context, forecast = dataset.test_data()\n",
    "    z, log_s_list, log_det_w_list, early_out_shapes = model(forecast, context)\n",
    "    \n",
    "    \n",
    "    checkpoint_path = \"%s/finalmodel_waveglow_ncontextchannels-%d_nflows-%d_ngroup-%d-nearlyevery-%d-nearlysize-%d-nlayers-%d_dilations-%s_nchannels_%d-kernelsize-%d-lr-%.5f_seed-%d_epoch-%d_loss-%.4f\" % (output_directory, params[0], params[1], params[2], params[3], params[4], params[5], str(params[6]), params[7], params[8], learning_rate, seed, epoch, epoch_loss)\n",
    "    save_checkpoint(model, optimizer, learning_rate, iteration, checkpoint_path, use_gpu)\n",
    "    loss = criterion((z, log_s_list, log_det_w_list))\n",
    "    test_loss = loss.item()\n",
    "    print(\"Test loss for this model is %.5f\" % loss)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(loss_iteration)), np.log10(np.array(loss_iteration)+1.0))\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('log10 of loss')\n",
    "    plt.savefig('total_loss_graph.png')\n",
    "    plt.close()\n",
    "    return test_loss, model\n",
    "\n",
    "def generate_tests(dataset, model, num_contexts=15, n=96, use_gpu=True, epoch='final', batch_size=24):\n",
    "    context, forecast = dataset.test_samples(num_contexts=15)\n",
    "\n",
    "    if use_gpu:\n",
    "        context = torch.cuda.FloatTensor(context)\n",
    "    else:\n",
    "        context = torch.FloatTensor(context)\n",
    "\n",
    "    if use_gpu:\n",
    "        gen_forecast = model.generate(context).cpu()\n",
    "    else:\n",
    "        gen_forecast = model.generate(context)\n",
    "\n",
    "    for i in range(num_contexts):\n",
    "        plt.figure()\n",
    "        plt.plot(range(n), gen_forecast[i, :], label='generated')\n",
    "        plt.plot(range(n), forecast[i, :], label='original')\n",
    "        plt.legend()\n",
    "        plt.xlabel('time (t)')\n",
    "        plt.savefig('forecast_generated_%d_epoch-%s.png' % (i, epoch))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def training_generator(config, epochs=100, batch_size=24, generate_per_epoch=True, checkpointing=False, use_gpu=False, n_channels=96, n_context_channels=96, rolling=True, dataset=None):\n",
    "    # n_context_channels=96, n_flows=6, n_group=24, n_early_every=3, n_early_size=8, n_layers=2, dilation_list=[1,2], n_channels=96, kernel_size=3, use_gpu=True\n",
    "    # params = [96, 6, 24, 3, 8, 2, [1,2], 96, 3]\n",
    "    \n",
    "    print(os.getcwd())\n",
    "    print(\"asdasdasdasdasdasd********asdasdasdasdasdasd********asdasdasdasdasdasd********asdasdasdasdasdasd********asdasdasdasdasdasd********asdasdasdasdasdasd********\")\n",
    "    multiple = [1, 2]\n",
    "#     if config[\"multiple\"]==0:\n",
    "#         multiple = [1, 2]\n",
    "#     elif config[\"multiple\"]==1:\n",
    "#         multiple = [2, 4]\n",
    "    \n",
    "    print('first')\n",
    "    print(int((config[\"dilation_rate\"]*.25 + .25)*config[\"n_layers\"]))\n",
    "    print('second')\n",
    "    print(int((1-(config[\"dilation_rate\"]*.25 + .25))*config[\"n_layers\"]))\n",
    "    dilation_list = [multiple[0]]*int((config[\"dilation_rate\"]*.25 + .25)*config[\"n_layers\"]) + [multiple[1]]*int((1-(config[\"dilation_rate\"]*.25 + .25))*config[\"n_layers\"])\n",
    "    print(len(dilation_list))\n",
    "    print(config[\"n_layers\"])\n",
    "    params = [n_context_channels,\n",
    "                config[\"n_flows\"],\n",
    "                config[\"n_group\"],\n",
    "                config[\"n_early_every\"],\n",
    "                config[\"n_early_size\"],\n",
    "                config[\"n_layers\"],\n",
    "                dilation_list,\n",
    "                n_channels,\n",
    "                config[\"kernel_size\"]]\n",
    "    dataset = deepcopy(config[\"dataset\"])\n",
    "#     if dataset==None:\n",
    "#         dataset = DataLoader(rolling=rolling, small_subset=False)\n",
    "    test_loss, final_model = training_procedure(epochs=epochs, \n",
    "                            dataset=dataset, \n",
    "                            use_gpu=use_gpu, \n",
    "                            checkpointing=checkpointing, \n",
    "                            gen_tests=generate_per_epoch, \n",
    "                            batch_size=batch_size, \n",
    "                            learning_rate=config[\"learning_rate\"],\n",
    "                            params=params)\n",
    "    if generate_final:\n",
    "        generate_tests(dataset, final_model, use_gpu=use_gpu)\n",
    "        \n",
    "    return test_loss\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/9.57 GiB heap, 0.0/3.27 GiB objects\n",
      "Memory usage on this node: 9.7/16.0 GiB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/9.57 GiB heap, 0.0/3.27 GiB objects\n",
      "Memory usage on this node: 9.7/16.0 GiB\n",
      "Result logdir: /Users/DanielSalz/ray_results/training_generator\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - training_generator_1_dataset=<DataLoader.DataLoader object at 0x11d264c88>,dilation_rate=1,kernel_size=3,learning_rate=12,multiple=1,n_early_every=3,n_early_size=2,n_flows=6,n_group=24,n_layers=20:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m /Users/DanielSalz/ray_results/training_generator/training_generator_1_dataset=<DataLoader.DataLoader object at 0x11d264c88>,dilation_rate=1,kernel_size=3,learning_rate=12,multiple_2019-11-28_00-18-14251zkebm\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m asdasdasdasdasdasd********asdasdasdasdasdasd********asdasdasdasdasdasd********asdasdasdasdasdasd********asdasdasdasdasdasd********asdasdasdasdasdasd********\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m first\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m 10\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m second\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m 10\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m 20\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m 20\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m #############\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m Channels:  24\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m Channels:  24\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m Channels:  24\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m Channels:  22\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m Channels:  22\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m Channels:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-28 00:18:16,860\tERROR trial_runner.py:569 -- Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 351, in fetch_result\n",
      "    result = ray.get(trial_future[0])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/worker.py\", line 2121, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray_worker\u001b[39m (pid=92641, host=Daniels-MacBook-Pro-6.local)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/trainable.py\", line 176, in train\n",
      "    result = self._train()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 199, in _train\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 242, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray_worker\u001b[39m (pid=92641, host=Daniels-MacBook-Pro-6.local)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 97, in run\n",
      "    self._entrypoint()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 145, in entrypoint\n",
      "    return self._trainable_func(config, self._status_reporter)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 261, in _trainable_func\n",
      "    output = train_func(config, reporter)\n",
      "  File \"<ipython-input-76-187a12033924>\", line 202, in training_generator\n",
      "  File \"<ipython-input-76-187a12033924>\", line 86, in training_procedure\n",
      "TypeError: 'StatusReporter' object cannot be interpreted as an integer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m 2019-11-28 00:18:16,798\tERROR function_runner.py:103 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 97, in run\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 145, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m     return self._trainable_func(config, self._status_reporter)\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 261, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m     output = train_func(config, reporter)\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m   File \"<ipython-input-76-187a12033924>\", line 202, in training_generator\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m   File \"<ipython-input-76-187a12033924>\", line 86, in training_procedure\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m TypeError: 'StatusReporter' object cannot be interpreted as an integer\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m Exception in thread Thread-1:\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 116, in run\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 97, in run\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 145, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m     return self._trainable_func(config, self._status_reporter)\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 261, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m     output = train_func(config, reporter)\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m   File \"<ipython-input-76-187a12033924>\", line 202, in training_generator\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m   File \"<ipython-input-76-187a12033924>\", line 86, in training_procedure\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m TypeError: 'StatusReporter' object cannot be interpreted as an integer\n",
      "\u001b[2m\u001b[36m(pid=92641)\u001b[0m \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/9.57 GiB heap, 0.0/3.27 GiB objects\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Result logdir: /Users/DanielSalz/ray_results/training_generator\n",
      "Number of trials: 1 ({'ERROR': 1})\n",
      "ERROR trials:\n",
      " - training_generator_1_dataset=<DataLoader.DataLoader object at 0x11d264c88>,dilation_rate=1,kernel_size=3,learning_rate=12,multiple=1,n_early_every=3,n_early_size=2,n_flows=6,n_group=24,n_layers=20:\tERROR, 1 failures: /Users/DanielSalz/ray_results/training_generator/training_generator_1_dataset=<DataLoader.DataLoader object at 0x11d264c88>,dilation_rate=1,kernel_size=3,learning_rate=12,multiple_2019-11-28_00-18-14251zkebm/error_2019-11-28_00-18-16.txt\n",
      "\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [training_generator_1_dataset=<DataLoader.DataLoader object at 0x11d264c88>,dilation_rate=1,kernel_size=3,learning_rate=12,multiple=1,n_early_every=3,n_early_size=2,n_flows=6,n_group=24,n_layers=20])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-ee20a984a196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# scheduler = AsyncHyperBandScheduler(metric=\"test_loss\", mode=\"min\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_alg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, restore, search_alg, scheduler, with_server, server_port, verbose, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init, sync_function)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [training_generator_1_dataset=<DataLoader.DataLoader object at 0x11d264c88>,dilation_rate=1,kernel_size=3,learning_rate=12,multiple=1,n_early_every=3,n_early_size=2,n_flows=6,n_group=24,n_layers=20])"
     ]
    }
   ],
   "source": [
    "import ray, os\n",
    "from ray.tune import run\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "from hyperopt import hp\n",
    "\n",
    "\n",
    "    # n_context_channels=96, n_flows=6, n_group=24, \n",
    "    #n_early_every=3, n_early_size=8, \n",
    "    #n_layers=2, dilation_list=[1,2], n_channels=96, \n",
    "    #kernel_size=3, use_gpu=True\n",
    "    # params = [96, 6, 24, 3, 8, 2, [1,2], 96, 3]\n",
    "\n",
    "# kernel_sizes = [1, 2, 3, 4, 5, 6]\n",
    "dataset = DataLoader(rolling=True, small_subset=False)\n",
    "space = {'n_flows': hp.choice('n_flows', np.arange(6, 7, dtype=int)),\n",
    "        'n_group': hp.choice('n_group', np.arange(24, 25, dtype=int)),\n",
    "#         'n_early_every': hp.choice('n_early_every', np.arange(1, 3, dtype=int)),\n",
    "         'n_early_every': hp.choice('n_early_every', np.arange(3, 4, dtype=int)),\n",
    "        'n_early_size': hp.choice('n_early_size', np.arange(2, 8, dtype=int)),\n",
    "        'n_layers': hp.choice('n_layers', np.arange(20, 24, 4, dtype=int)),\n",
    "#         'dilation_rate': hp.choice('dilation_rate', [0, 1, 2, 3]),\n",
    "         'dilation_rate': hp.choice('dilation_rate', [0, 1]),\n",
    "        'multiple': hp.choice('multiple', [0, 1]),\n",
    "        'kernel_size': hp.choice('kernel_size', [1, 3]),\n",
    "        'learning_rate': hp.choice('learning_rate', np.arange(1, 20, dtype=int)),\n",
    "        'dataset': dataset}\n",
    "\n",
    "algo = HyperOptSearch(space, \n",
    "                      max_concurrent=1, \n",
    "                      mode=\"min\")\n",
    "\n",
    "# scheduler = AsyncHyperBandScheduler(metric=\"test_loss\", mode=\"min\")\n",
    "analysis = run(training_generator, search_alg=algo, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
